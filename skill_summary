

1. initialize:  
#open
myedit("plot1.R")
source(pathtofile("plot1.R"),local=TRUE)

#download 
if (!file.exists("data")){
        dir.create("data")
}
fileurl <- "https:..."
download.file(fileurl, destfile = "./data/aa.csv", method = "curl", mode = "wb") #curl for Mac #mode for Error in .jcall("RJavaTools", "Ljava/lang/Object;", 
dateDownload <- data() 
 
url = "https://d396qusza40orc.cloudfront.net/rprog%2Fdata%2FProgAssignment3-data.zip"
download.file(url, destfile = "temp")
unzip("temp")
unlink("temp")

#read CSV as table
data <- read.table("data.csv", sep = ",", header T, rownames, quote ="", nrow, skip, na.strings)  #don't read quotation mark 
data <- fread("survey.csv, sep = ",")
# READING MULTIPLE CSV
data <- read.csv(paste(directory,"/","0",i,".csv",sep = ""), header = TRUE)
rates <- read.csv("outcome-of-care-measures.csv", colClasses = "character")

aa <- read.csv("11.csv", skip = 4, nrows = 215) %>%
        subset(!is.na(X) & X != "", select = c("X","X.1","X.3","X.4"))%>%
        rename(CountryCode = "X", rankingGDP = "X.1", Long.Name = "X.3", gdp = "X.4")


#write 
write.table(final_data, file = "final_data.txt", row.name=FALSE)


#initialize
allData <- numeric()
comp <- data.frame(id=numeric(length(1:4)), nobs=numeric(length(1:4)))
airquality <- transform(airquality, month = factor(month))

#OMIT NA 
mean(allData, na.rm=TRUE)
data2 <- na.omit(data) 
cor(a,b, use = "complete.obs")


#list 

l1 <- list(a = "a", b = 2, c = pi+2i)
unlist(l1)


 
2. simulation 
sample(colors(),10)
 sample(1:6, 4, replace = TRUE) #select 4 number from 1:6 
 flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))


seq(0,1,len=6)
rep(0:1, each = 50 )


> rbinom (1, size = 100, prob = 0.7)
[1] 61              # a single random variable that represents the number of heads in 100 flips of our unfair coin
> flips2 <- rbinom(100, size = 1, prob = 0.7)
  [1] 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0
 [34] 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1
 [67] 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0
[100] 1

> rnorm(10, mean = 100, sd = 25)
 [1] 123.55667 107.49630  92.58885 111.22653 107.79632  74.79879
 [7]  99.03713  99.43503 118.14440  91.25727
#pnorm 
> pnorm(100, 50, lower.tail = F)
[1] 0
> pnorm(100,50)
[1] 1
> pnorm(50,50)
[1] 0.5




3.screening and change value 
#select() slect the column


#filter(), filter the row 


#arrange()
top_counts_sorted <- arrange(top_counts, desc(count))


#mutate
mutate(size_mb = size/ 2^20)


#which
which(state_data[,11] == min(state_data[,11],na.rm = T))      #return the number of row of min 
 
state_data <- outcame[outcame$State == state, ]

maxInt <- data[which.max(data$steps),]
same as :max_steps <- data[which(data$steps == max(data$steps)),] 


#subset $ normal 
aa <- data.frame(a = 1:5,c =c("a","b","c","d","e"), b =c(21,23,444,1,20))
bb <- subset.data.frame(aa, select = c (a,b))

subset(pollution, region == "west")$pm25

complete1_subset <- subset(complete1, nobs > threshold)
 
answer5 <- DT[Income.Group == "Lower middle income", ]


#data.frame 
observedcase <- data.frame(id = numeric(length(id)), nobs= numeric(length(id)))
observedcase[["id"]][count] <- i
observedcase[["nobs"]][count] <- nobs
i in observations$id[observations$nobs > threshold]
train <- data.frame(subject_train, activity_train, X_train) #merging data 

#factor 
meanstd_data$activity <- factor(meanstd_data$activity, levels = activity_labels[,1], labels = activity_labels[,2])
airquality <- transform(airquality, month = factor(month))

 
4. order 
#order 
aa <- data.frame(a = 1:5,c =c("a","b","c","d","e"), b =c(21,23,444,1,20))
bb <- aa[order(aa$b, aa$b),]   #as a entire to order, first to order by the first and then order by the second  
order <- data_state[order(data_state[,11], data_state[,2], na.last = NA), ]
#sort
> sort(aa$b)
[1]   1  20  21  23 444
#rank 
> rank(aa$b)
#arrange 
 require(plyr)
order_selected <- arrange(selected_state, selected_state[,outcome], Hospital.Name, na.last=TRUE)
  same:  order <- data_state[order(data_state[,11], data_state[,2], na.last = NA), ]

#clear 
!!! every time try a new sample, clear the environment first. 
[1] 3 4 5 1 2



5. Detection 
# T& F
 if (!outcome %in% c( "heart attack","heart failure","pneumonia")){
 aa <- "invaid outcome"
  if (!state %in% unique(rates$State))
 return("Invalid State")
 
 
 6. multiple function 
 #*apply 
dim(flags)
[1] 194  30    # 194 rows, and 30 columns
mortality_rates[,c(3,4,5)] <- apply(mortality_rates[,3:5],2,as.numeric)
sapply(flag_shapes, range)  # the min and max value of each column
sapply(flags, unique) # returns a list containing one vector of unique values for each column of the flags dataset
vapply(flags, unique, numeric(1))  #  a safer than sapply : error if each element of the result to be NOT a numeric vector of length 1
table(flags$landmass)
 1  2  3  4  5  6 
31 17 35 52 39 20     # the number of every level 
tapply(flags$animate, flags$landmass, mean)    
  1         2         3         4         5         6 
0.4193548 0.1764706 0.1142857 0.1346154 0.1538462 0.3000000     #to apply the mean function to the 'animate' variable separately
                                                                for each of the six landmass groups. split your data
                                                                into groups based on the value of some variable, then apply a
                                                                function to each group.                                                                
tapply(mtcars$mpg, mtcars$cyl, mean) == sapply(split(mtcars$mpg, mtcars$cyl), mean) == with(mtcars, tapply(mpg, cyl, mean))                                                                 




7. summary and reshaping 
#tbl
cran <- tbl_df(mydf)


#view 
head() 
tail()
range( ... , na.rm = T) 
dim()
table()

#str 


#smmarise 
summarise(by_package, mean(size))


#group_by 
by_package <- group_by(cran, package)

pack_sum <- summarize(by_package,count = n(),unique = n_distinct(ip_id),countries = n_distinct(country),avg_bytes = mean(size) )

quantile(pack_sum$count, probs = 0.99)

View(top_counts)

df_data_averaged <- df_data_reduced %>%group_by(subject, activity) %>% summarize_all(funs(mean)) %>% arrange(subject)


#table 
table(matchedData$Income.Group, matchedData$Rank.Groups)
##                         [  1, 39) [ 39, 77) [ 77,115) [115,154) [154,190]
## High income: nonOECD         4         5         8         5         1
## High income: OECD           18        10         1         1         0
## Low income                   0         1         9        16        11
## Lower middle income          *5*        13        12         8        16
## Upper middle income         11         9         8         8         9

addmargins(table(year(sampleTimes), weekdays(sampleTimes))) #add the sum 

table(diamonds$color, diamonds$cut)


#melt & dcast   # turn one column into variable
melted <- melt(data5, id=c("subject","activity"))
tidy <- dcast(melted, subject+activity ~ variable, mean)


bb <- melt(final_data, id = c("subject","activity"))
cc <- dcast(bb, subject ~ activity, sum)


#aggregate 
data.tidy <- aggregate(data.sub[,3:81], by = list(activity = data.sub$activity, subject = data.sub$subject),FUN = mean)


#merge 
cc<- merge(aa,bb, by = "CountryCode", all = T)
 
 
#cut2
library(Hmisc)
matchedData$Rank.Groups = cut2(matchedData$Rank, g = 5)
table(matchedData$Income.Group, matchedData$Rank.Groups) 



8. editing text and index  
#index
index <- c(grep("^Hospital.*Death*", names(rates)))  # ^ means the first letter, careful the capital 


#names and editing text 
names(mortality_rates)[3:5] <- c("heart attack", "heart failure", "pneumonia")
 rename(CountryCode = "X", rankingGDP = "X.1", Long.Name = "X.3", gdp = "X.4")

names(cameraData)
tolower(names(cameraData)  #lowercase all letters
toupper(names()) #oppsise

splitnames <- strsplit(names(cameraData), "\\.") # split the "."
firstElement <- function(x){x[1]} 
sapply(splitnames, firstElement) 
bb <- strsplit(names(aa), "wgtp")   # remove the "wgtp"from all names 

sub("_","",names(reviews),) #remove first "_" 
gsub("_","",names(reviews),)  #remove mutiple "_"
names(data4) <- gsub("^f","FrequencyDomain-",names(data4))
names(data4) <- gsub("[(][)]","",names(data4))
featuresWanted.names <- gsub('[-()]', '', featuresWanted.names)
names(data4) <- gsub("Body","Body-",names(data4))
featuresWanted <- grep(".*mean.*|.*std.*", features[,2])


substr("jeffrey leek",1,7) # get the 1 to 7 characters of the strings 

paste("jeffrey", "leek", sep = "-")  # get space in between without sep. 
paste0("jeffrey","leek") # get "jeffreyleek"

grep("Alameda", cameraData$intersection) # finding values, return the location(which) 
grepl("Alameda", cameraData$intersection) #return the logical vector 
grep("Alameda", cameraData$intersection, value =T)#return the original strings 

library(stringr) 
nchar("jeffrey leek") #return the number of appear time 

str_trim("jeff    ") #get "jeff"


#regular expressions
^i think #represents the first 
moring$ #represents the end of a line
[Bb][Uu][Ss][Hh]
^[Ii] am 
^[0-9][a-zA-Z]  # get  "7th..."
[^?.]$  #means all line ending by "? and ." will be delete
9.11  #refer to any character 9-11, 9:11 911 9/11
flood|fire # any line has either of flood and fire.
^[Gg]ood | [Bb]ad 
^([Gg]ood | [Bb]ad )
[Gg]eorge( [Ww]\.)? [Bb]ush # question mark indicates   optional. 
\. # means it is literal dot rather than a metacharacter.
(.*) #anything in the ()
[0-9]+ (.*) [0-9]+  # 720 dhvnef 43; 23 or 433; 
[Bb]ush( +[^ ]+ +){1,5} debate
 +([a-zA-Z]+) +\1 + # so so ; blah blah 
  
  
  
9.   base graphics 
| Before plotting, it is always a good idea to get a sense of the data.
| Key R commands for doing so include, dim(), names(), head(), tail()
| and summary().
 
 plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
 plot(cars, main = "My Plot", sub = "My Plot Subtitle", xlim = c(10, 15), col = 2, pch = 2) # color is red, shape is triangle 
 
 > boxplot(mpg ~ cyl, data = mtcars)
 
 > ggplot(mtcars, aes(x=mpg, y=wt, colour=cyl)) +geom_point()  

other 
min <- .Machine$integer.max
use chain %>% 
data see 2.tidy day 
graphic see 3. explotary data  or lubridate package 
color see  3. explotary data 


